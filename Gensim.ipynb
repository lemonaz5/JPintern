{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try  gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",              \n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of frequent words\n",
    "stoplist = set('for a of the and to in'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in raw_corpus]\n",
    "\n",
    "# Count word frequencies\n",
    "#from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(1, 1), (5, 2), (8, 1)],\n",
       " [(3, 1), (6, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(4, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.5898341626740045), (11, 0.8075244024440723)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from gensim import models\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "# transform the \"system minors\" string\n",
    "tfidf[dictionary.doc2bow(\"system minors\".lower().split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 0.8075244024440723), (10, 0.5898341626740045)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[dictionary.doc2bow(\"time graph\".lower().split())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(file, obj):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_obj(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\sociocom\\Desktop\\Crawler\\backup\\31May-4June 2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spl = load_obj(path + r\"\\translated_spl_tweet\")\n",
    "df_bkk = load_obj(path + r\"\\translated_bkk_tweet\")\n",
    "df_ham = load_obj(path + r\"\\translated_ham_tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>acc</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_time</th>\n",
       "      <th>ex_lat</th>\n",
       "      <th>ex_long</th>\n",
       "      <th>place</th>\n",
       "      <th>lot_sw</th>\n",
       "      <th>lot_ne</th>\n",
       "      <th>tweet_reply_id</th>\n",
       "      <th>tweet_reply_user_id</th>\n",
       "      <th>tweet_reply_username</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196292182016</td>\n",
       "      <td>Police Düren - driver flung out of the car aft...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196334096384</td>\n",
       "      <td>Police Neustadt bei Coburg - Without license o...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196317270017</td>\n",
       "      <td>Police Gädheim - gelding with enigmatic neck i...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196304695297</td>\n",
       "      <td>Polizeipräsidium Südosthessen - Offenbach - Pr...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196296355840</td>\n",
       "      <td>Police Neustadt bei Coburg - Accident Exodus h...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc_id             acc             tweet_id  \\\n",
       "0  855881532145360896  focus_regional  1002062196292182016   \n",
       "1  855881532145360896  focus_regional  1002062196334096384   \n",
       "2  855881532145360896  focus_regional  1002062196317270017   \n",
       "3  855881532145360896  focus_regional  1002062196304695297   \n",
       "4  855881532145360896  focus_regional  1002062196296355840   \n",
       "\n",
       "                                                text         created_time  \\\n",
       "0  Police Düren - driver flung out of the car aft...  2018-05-31 05:40:19   \n",
       "1  Police Neustadt bei Coburg - Without license o...  2018-05-31 05:40:19   \n",
       "2  Police Gädheim - gelding with enigmatic neck i...  2018-05-31 05:40:19   \n",
       "3  Polizeipräsidium Südosthessen - Offenbach - Pr...  2018-05-31 05:40:19   \n",
       "4  Police Neustadt bei Coburg - Accident Exodus h...  2018-05-31 05:40:19   \n",
       "\n",
       "  ex_lat ex_long    place               lot_sw                lot_ne  \\\n",
       "0     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "1     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "2     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "3     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "4     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "\n",
       "  tweet_reply_id tweet_reply_user_id tweet_reply_username lang  \n",
       "0             -1                  -1                   -1   de  \n",
       "1             -1                  -1                   -1   de  \n",
       "2             -1                  -1                   -1   de  \n",
       "3             -1                  -1                   -1   de  \n",
       "4             -1                  -1                   -1   de  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37095"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>acc</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_time</th>\n",
       "      <th>ex_lat</th>\n",
       "      <th>ex_long</th>\n",
       "      <th>place</th>\n",
       "      <th>lot_sw</th>\n",
       "      <th>lot_ne</th>\n",
       "      <th>tweet_reply_id</th>\n",
       "      <th>tweet_reply_user_id</th>\n",
       "      <th>tweet_reply_username</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>880139242558676993</td>\n",
       "      <td>gu3ds_</td>\n",
       "      <td>1002070123061051392</td>\n",
       "      <td>I just think it's funny how the debauch hj ta ...</td>\n",
       "      <td>2018-05-31 06:11:49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71562250</td>\n",
       "      <td>Alexrodrigues73</td>\n",
       "      <td>1002070143873245184</td>\n",
       "      <td>@IvanCarlus @eaglesaopaulo kkkkkkkkk.... cai m...</td>\n",
       "      <td>2018-05-31 06:11:54</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>1002023363378851841</td>\n",
       "      <td>47545111</td>\n",
       "      <td>IvanCarlus</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>883893293465186304</td>\n",
       "      <td>ester_querinoo</td>\n",
       "      <td>1002070146721222657</td>\n",
       "      <td>Mother, everything that comes from you to me i...</td>\n",
       "      <td>2018-05-31 06:11:55</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4794804172</td>\n",
       "      <td>elizaberh_costa</td>\n",
       "      <td>1002070147404828672</td>\n",
       "      <td>General sleeping</td>\n",
       "      <td>2018-05-31 06:11:55</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33572317</td>\n",
       "      <td>thelukeset</td>\n",
       "      <td>1002070200508932096</td>\n",
       "      <td>people this series 13 reasons why eh mto compl...</td>\n",
       "      <td>2018-05-31 06:12:08</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc_id              acc             tweet_id  \\\n",
       "0  880139242558676993           gu3ds_  1002070123061051392   \n",
       "1            71562250  Alexrodrigues73  1002070143873245184   \n",
       "2  883893293465186304   ester_querinoo  1002070146721222657   \n",
       "3          4794804172  elizaberh_costa  1002070147404828672   \n",
       "4            33572317       thelukeset  1002070200508932096   \n",
       "\n",
       "                                                text         created_time  \\\n",
       "0  I just think it's funny how the debauch hj ta ...  2018-05-31 06:11:49   \n",
       "1  @IvanCarlus @eaglesaopaulo kkkkkkkkk.... cai m...  2018-05-31 06:11:54   \n",
       "2  Mother, everything that comes from you to me i...  2018-05-31 06:11:55   \n",
       "3                                   General sleeping  2018-05-31 06:11:55   \n",
       "4  people this series 13 reasons why eh mto compl...  2018-05-31 06:12:08   \n",
       "\n",
       "  ex_lat ex_long      place                  lot_sw                  lot_ne  \\\n",
       "0     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "1     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "2     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "3     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "4     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "\n",
       "        tweet_reply_id tweet_reply_user_id tweet_reply_username lang  \n",
       "0                   -1                  -1                   -1   pt  \n",
       "1  1002023363378851841            47545111           IvanCarlus   pt  \n",
       "2                   -1                  -1                   -1   pt  \n",
       "3                   -1                  -1                   -1   pt  \n",
       "4                   -1                  -1                   -1   pt  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'people this series 13 reasons why eh mto complicated ne still good that there are some warnings'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spl[\"text\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Horrible !! Sathorn Taksin Express Boat or Boat'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bkk[\"text\"][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
