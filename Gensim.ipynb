{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try  gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sociocom\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",              \n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of frequent words\n",
    "stoplist = set('for a of the and to in'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in raw_corpus]\n",
    "\n",
    "# Count word frequencies\n",
    "#from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(1, 1), (5, 2), (8, 1)],\n",
       " [(3, 1), (6, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(4, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.5898341626740045), (11, 0.8075244024440723)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from gensim import models\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "# transform the \"system minors\" string\n",
    "tfidf[dictionary.doc2bow(\"system minors\".lower().split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 0.8075244024440723), (10, 0.5898341626740045)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[dictionary.doc2bow(\"time graph\".lower().split())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(file, obj):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_obj(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\sociocom\\Desktop\\Crawler\\backup\\31May-4June 2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spl = load_obj(path + r\"\\translated_spl_tweet\")\n",
    "df_bkk = load_obj(path + r\"\\translated_bkk_tweet\")\n",
    "df_ham = load_obj(path + r\"\\translated_ham_tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>acc</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_time</th>\n",
       "      <th>ex_lat</th>\n",
       "      <th>ex_long</th>\n",
       "      <th>place</th>\n",
       "      <th>lot_sw</th>\n",
       "      <th>lot_ne</th>\n",
       "      <th>tweet_reply_id</th>\n",
       "      <th>tweet_reply_user_id</th>\n",
       "      <th>tweet_reply_username</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196292182016</td>\n",
       "      <td>Police Düren - driver flung out of the car aft...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196334096384</td>\n",
       "      <td>Police Neustadt bei Coburg - Without license o...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196317270017</td>\n",
       "      <td>Police Gädheim - gelding with enigmatic neck i...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196304695297</td>\n",
       "      <td>Polizeipräsidium Südosthessen - Offenbach - Pr...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>855881532145360896</td>\n",
       "      <td>focus_regional</td>\n",
       "      <td>1002062196296355840</td>\n",
       "      <td>Police Neustadt bei Coburg - Accident Exodus h...</td>\n",
       "      <td>2018-05-31 05:40:19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.866357, 47.270127</td>\n",
       "      <td>15.041854, 55.056823</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc_id             acc             tweet_id  \\\n",
       "0  855881532145360896  focus_regional  1002062196292182016   \n",
       "1  855881532145360896  focus_regional  1002062196334096384   \n",
       "2  855881532145360896  focus_regional  1002062196317270017   \n",
       "3  855881532145360896  focus_regional  1002062196304695297   \n",
       "4  855881532145360896  focus_regional  1002062196296355840   \n",
       "\n",
       "                                                text         created_time  \\\n",
       "0  Police Düren - driver flung out of the car aft...  2018-05-31 05:40:19   \n",
       "1  Police Neustadt bei Coburg - Without license o...  2018-05-31 05:40:19   \n",
       "2  Police Gädheim - gelding with enigmatic neck i...  2018-05-31 05:40:19   \n",
       "3  Polizeipräsidium Südosthessen - Offenbach - Pr...  2018-05-31 05:40:19   \n",
       "4  Police Neustadt bei Coburg - Accident Exodus h...  2018-05-31 05:40:19   \n",
       "\n",
       "  ex_lat ex_long    place               lot_sw                lot_ne  \\\n",
       "0     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "1     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "2     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "3     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "4     -1      -1  Germany  5.866357, 47.270127  15.041854, 55.056823   \n",
       "\n",
       "  tweet_reply_id tweet_reply_user_id tweet_reply_username lang  \n",
       "0             -1                  -1                   -1   de  \n",
       "1             -1                  -1                   -1   de  \n",
       "2             -1                  -1                   -1   de  \n",
       "3             -1                  -1                   -1   de  \n",
       "4             -1                  -1                   -1   de  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37095"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>acc</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_time</th>\n",
       "      <th>ex_lat</th>\n",
       "      <th>ex_long</th>\n",
       "      <th>place</th>\n",
       "      <th>lot_sw</th>\n",
       "      <th>lot_ne</th>\n",
       "      <th>tweet_reply_id</th>\n",
       "      <th>tweet_reply_user_id</th>\n",
       "      <th>tweet_reply_username</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>880139242558676993</td>\n",
       "      <td>gu3ds_</td>\n",
       "      <td>1002070123061051392</td>\n",
       "      <td>I just think it's funny how the debauch hj ta ...</td>\n",
       "      <td>2018-05-31 06:11:49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71562250</td>\n",
       "      <td>Alexrodrigues73</td>\n",
       "      <td>1002070143873245184</td>\n",
       "      <td>@IvanCarlus @eaglesaopaulo kkkkkkkkk.... cai m...</td>\n",
       "      <td>2018-05-31 06:11:54</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>1002023363378851841</td>\n",
       "      <td>47545111</td>\n",
       "      <td>IvanCarlus</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>883893293465186304</td>\n",
       "      <td>ester_querinoo</td>\n",
       "      <td>1002070146721222657</td>\n",
       "      <td>Mother, everything that comes from you to me i...</td>\n",
       "      <td>2018-05-31 06:11:55</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4794804172</td>\n",
       "      <td>elizaberh_costa</td>\n",
       "      <td>1002070147404828672</td>\n",
       "      <td>General sleeping</td>\n",
       "      <td>2018-05-31 06:11:55</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33572317</td>\n",
       "      <td>thelukeset</td>\n",
       "      <td>1002070200508932096</td>\n",
       "      <td>people this series 13 reasons why eh mto compl...</td>\n",
       "      <td>2018-05-31 06:12:08</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-46.826039, -24.008814</td>\n",
       "      <td>-46.365052, -23.356792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc_id              acc             tweet_id  \\\n",
       "0  880139242558676993           gu3ds_  1002070123061051392   \n",
       "1            71562250  Alexrodrigues73  1002070143873245184   \n",
       "2  883893293465186304   ester_querinoo  1002070146721222657   \n",
       "3          4794804172  elizaberh_costa  1002070147404828672   \n",
       "4            33572317       thelukeset  1002070200508932096   \n",
       "\n",
       "                                                text         created_time  \\\n",
       "0  I just think it's funny how the debauch hj ta ...  2018-05-31 06:11:49   \n",
       "1  @IvanCarlus @eaglesaopaulo kkkkkkkkk.... cai m...  2018-05-31 06:11:54   \n",
       "2  Mother, everything that comes from you to me i...  2018-05-31 06:11:55   \n",
       "3                                   General sleeping  2018-05-31 06:11:55   \n",
       "4  people this series 13 reasons why eh mto compl...  2018-05-31 06:12:08   \n",
       "\n",
       "  ex_lat ex_long      place                  lot_sw                  lot_ne  \\\n",
       "0     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "1     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "2     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "3     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "4     -1      -1  Sao Paulo  -46.826039, -24.008814  -46.365052, -23.356792   \n",
       "\n",
       "        tweet_reply_id tweet_reply_user_id tweet_reply_username lang  \n",
       "0                   -1                  -1                   -1   pt  \n",
       "1  1002023363378851841            47545111           IvanCarlus   pt  \n",
       "2                   -1                  -1                   -1   pt  \n",
       "3                   -1                  -1                   -1   pt  \n",
       "4                   -1                  -1                   -1   pt  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'people this series 13 reasons why eh mto complicated ne still good that there are some warnings'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spl[\"text\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Horrible !! Sathorn Taksin Express Boat or Boat'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bkk[\"text\"][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try gensim doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file names for train and test data\n",
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])\n",
    "lee_train_file = test_data_dir + os.sep + 'lee_background.cor'\n",
    "lee_test_file = test_data_dir + os.sep + 'lee.cor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sociocom\\\\Anaconda3\\\\lib\\\\site-packages\\\\gensim\\\\test\\\\test_data\\\\lee.cor'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lee_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bladfmos', 'dfo', 'fg', 'not']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.utils.simple_preprocess(\"bladfmos \\n dfo fg I'm not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.smart_open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['hundreds', 'of', 'people', 'have', 'been', 'forced', 'to', 'vacate', 'their', 'homes', 'in', 'the', 'southern', 'highlands', 'of', 'new', 'south', 'wales', 'as', 'strong', 'winds', 'today', 'pushed', 'huge', 'bushfire', 'towards', 'the', 'town', 'of', 'hill', 'top', 'new', 'blaze', 'near', 'goulburn', 'south', 'west', 'of', 'sydney', 'has', 'forced', 'the', 'closure', 'of', 'the', 'hume', 'highway', 'at', 'about', 'pm', 'aedt', 'marked', 'deterioration', 'in', 'the', 'weather', 'as', 'storm', 'cell', 'moved', 'east', 'across', 'the', 'blue', 'mountains', 'forced', 'authorities', 'to', 'make', 'decision', 'to', 'evacuate', 'people', 'from', 'homes', 'in', 'outlying', 'streets', 'at', 'hill', 'top', 'in', 'the', 'new', 'south', 'wales', 'southern', 'highlands', 'an', 'estimated', 'residents', 'have', 'left', 'their', 'homes', 'for', 'nearby', 'mittagong', 'the', 'new', 'south', 'wales', 'rural', 'fire', 'service', 'says', 'the', 'weather', 'conditions', 'which', 'caused', 'the', 'fire', 'to', 'burn', 'in', 'finger', 'formation', 'have', 'now', 'eased', 'and', 'about', 'fire', 'units', 'in', 'and', 'around', 'hill', 'top', 'are', 'optimistic', 'of', 'defending', 'all', 'properties', 'as', 'more', 'than', 'blazes', 'burn', 'on', 'new', 'year', 'eve', 'in', 'new', 'south', 'wales', 'fire', 'crews', 'have', 'been', 'called', 'to', 'new', 'fire', 'at', 'gunning', 'south', 'of', 'goulburn', 'while', 'few', 'details', 'are', 'available', 'at', 'this', 'stage', 'fire', 'authorities', 'says', 'it', 'has', 'closed', 'the', 'hume', 'highway', 'in', 'both', 'directions', 'meanwhile', 'new', 'fire', 'in', 'sydney', 'west', 'is', 'no', 'longer', 'threatening', 'properties', 'in', 'the', 'cranebrook', 'area', 'rain', 'has', 'fallen', 'in', 'some', 'parts', 'of', 'the', 'illawarra', 'sydney', 'the', 'hunter', 'valley', 'and', 'the', 'north', 'coast', 'but', 'the', 'bureau', 'of', 'meteorology', 'claire', 'richards', 'says', 'the', 'rain', 'has', 'done', 'little', 'to', 'ease', 'any', 'of', 'the', 'hundred', 'fires', 'still', 'burning', 'across', 'the', 'state', 'the', 'falls', 'have', 'been', 'quite', 'isolated', 'in', 'those', 'areas', 'and', 'generally', 'the', 'falls', 'have', 'been', 'less', 'than', 'about', 'five', 'millimetres', 'she', 'said', 'in', 'some', 'places', 'really', 'not', 'significant', 'at', 'all', 'less', 'than', 'millimetre', 'so', 'there', 'hasn', 'been', 'much', 'relief', 'as', 'far', 'as', 'rain', 'is', 'concerned', 'in', 'fact', 'they', 've', 'probably', 'hampered', 'the', 'efforts', 'of', 'the', 'firefighters', 'more', 'because', 'of', 'the', 'wind', 'gusts', 'that', 'are', 'associated', 'with', 'those', 'thunderstorms'], tags=[0]),\n",
       " TaggedDocument(words=['indian', 'security', 'forces', 'have', 'shot', 'dead', 'eight', 'suspected', 'militants', 'in', 'night', 'long', 'encounter', 'in', 'southern', 'kashmir', 'the', 'shootout', 'took', 'place', 'at', 'dora', 'village', 'some', 'kilometers', 'south', 'of', 'the', 'kashmiri', 'summer', 'capital', 'srinagar', 'the', 'deaths', 'came', 'as', 'pakistani', 'police', 'arrested', 'more', 'than', 'two', 'dozen', 'militants', 'from', 'extremist', 'groups', 'accused', 'of', 'staging', 'an', 'attack', 'on', 'india', 'parliament', 'india', 'has', 'accused', 'pakistan', 'based', 'lashkar', 'taiba', 'and', 'jaish', 'mohammad', 'of', 'carrying', 'out', 'the', 'attack', 'on', 'december', 'at', 'the', 'behest', 'of', 'pakistani', 'military', 'intelligence', 'military', 'tensions', 'have', 'soared', 'since', 'the', 'raid', 'with', 'both', 'sides', 'massing', 'troops', 'along', 'their', 'border', 'and', 'trading', 'tit', 'for', 'tat', 'diplomatic', 'sanctions', 'yesterday', 'pakistan', 'announced', 'it', 'had', 'arrested', 'lashkar', 'taiba', 'chief', 'hafiz', 'mohammed', 'saeed', 'police', 'in', 'karachi', 'say', 'it', 'is', 'likely', 'more', 'raids', 'will', 'be', 'launched', 'against', 'the', 'two', 'groups', 'as', 'well', 'as', 'other', 'militant', 'organisations', 'accused', 'of', 'targetting', 'india', 'military', 'tensions', 'between', 'india', 'and', 'pakistan', 'have', 'escalated', 'to', 'level', 'not', 'seen', 'since', 'their', 'war'], tags=[1])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab['penalty'].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.71 s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0344929 , -0.03458783, -0.20483422, -0.01532167,  0.08419161,\n",
       "        0.01290932, -0.0061182 , -0.02686771, -0.07614843,  0.02154057,\n",
       "       -0.09797131, -0.04613339,  0.12928651, -0.00275543,  0.12938412,\n",
       "        0.01080016, -0.01385127,  0.10651631,  0.10738748,  0.14092727,\n",
       "        0.02874154, -0.04150788, -0.07247101, -0.00521359, -0.13875784,\n",
       "       -0.10670739,  0.06430835,  0.10053124,  0.11352053, -0.0054336 ,\n",
       "       -0.00696253, -0.01372416, -0.18471897,  0.02248359,  0.1084251 ,\n",
       "        0.12050885,  0.00948765, -0.16709426,  0.05051792,  0.01660123,\n",
       "        0.10350799,  0.08469869,  0.04221268,  0.09002685,  0.11598106,\n",
       "        0.12410803,  0.1304872 ,  0.07409295, -0.08350455,  0.06319322],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(['only', 'you', 'can', 'help', 'me'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 290, 1: 8, 2: 2})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(ranks)  # Results vary due to random seeding and very small corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(299, 0.9568108320236206),\n",
       " (55, 0.7961515784263611),\n",
       " (17, 0.7892531156539917),\n",
       " (112, 0.7834669947624207),\n",
       " (104, 0.7814677953720093),\n",
       " (146, 0.744698703289032),\n",
       " (275, 0.7389845848083496),\n",
       " (59, 0.7208225727081299),\n",
       " (191, 0.7076708078384399),\n",
       " (72, 0.7013301849365234),\n",
       " (139, 0.7003688812255859),\n",
       " (182, 0.6984608173370361),\n",
       " (6, 0.6966038942337036),\n",
       " (16, 0.6868076324462891),\n",
       " (37, 0.6813418865203857),\n",
       " (283, 0.6745368242263794),\n",
       " (258, 0.6619173288345337),\n",
       " (47, 0.6282996535301208),\n",
       " (118, 0.6209578514099121),\n",
       " (215, 0.6108769178390503),\n",
       " (207, 0.6057468056678772),\n",
       " (132, 0.5977011919021606),\n",
       " (158, 0.5702075958251953),\n",
       " (180, 0.555284857749939),\n",
       " (246, 0.554865300655365),\n",
       " (241, 0.5465972423553467),\n",
       " (232, 0.5462438464164734),\n",
       " (26, 0.5452182292938232),\n",
       " (280, 0.533488392829895),\n",
       " (293, 0.5307345986366272),\n",
       " (266, 0.5306819081306458),\n",
       " (71, 0.5144978165626526),\n",
       " (111, 0.5107663869857788),\n",
       " (70, 0.5079542994499207),\n",
       " (42, 0.5043641328811646),\n",
       " (196, 0.49088382720947266),\n",
       " (96, 0.49081236124038696),\n",
       " (165, 0.48511409759521484),\n",
       " (224, 0.4682495594024658),\n",
       " (294, 0.4600104093551636),\n",
       " (38, 0.4572696387767792),\n",
       " (190, 0.4565918743610382),\n",
       " (83, 0.4520495533943176),\n",
       " (152, 0.44664496183395386),\n",
       " (130, 0.44437524676322937),\n",
       " (73, 0.43864142894744873),\n",
       " (92, 0.4330790042877197),\n",
       " (64, 0.43133169412612915),\n",
       " (45, 0.42252081632614136),\n",
       " (228, 0.4213308095932007),\n",
       " (53, 0.41795122623443604),\n",
       " (225, 0.4155891239643097),\n",
       " (52, 0.41223055124282837),\n",
       " (23, 0.4083450734615326),\n",
       " (27, 0.4018706977367401),\n",
       " (7, 0.397597074508667),\n",
       " (157, 0.3962036073207855),\n",
       " (186, 0.38862329721450806),\n",
       " (175, 0.38272592425346375),\n",
       " (221, 0.37996867299079895),\n",
       " (15, 0.37917155027389526),\n",
       " (271, 0.3758389353752136),\n",
       " (289, 0.3757258653640747),\n",
       " (263, 0.3746809959411621),\n",
       " (269, 0.3697621822357178),\n",
       " (39, 0.3656628727912903),\n",
       " (32, 0.3633553087711334),\n",
       " (254, 0.36306893825531006),\n",
       " (115, 0.35879388451576233),\n",
       " (274, 0.355876088142395),\n",
       " (245, 0.3553231358528137),\n",
       " (61, 0.353982150554657),\n",
       " (282, 0.353322297334671),\n",
       " (19, 0.35266774892807007),\n",
       " (119, 0.3496888279914856),\n",
       " (181, 0.3491283357143402),\n",
       " (214, 0.3482804000377655),\n",
       " (43, 0.3478333055973053),\n",
       " (264, 0.3431684970855713),\n",
       " (297, 0.3400615453720093),\n",
       " (90, 0.33903104066848755),\n",
       " (46, 0.3389539122581482),\n",
       " (218, 0.3364608585834503),\n",
       " (134, 0.3323912024497986),\n",
       " (213, 0.327725350856781),\n",
       " (194, 0.3253609836101532),\n",
       " (174, 0.32273662090301514),\n",
       " (229, 0.32002443075180054),\n",
       " (253, 0.3145938515663147),\n",
       " (212, 0.31294935941696167),\n",
       " (18, 0.31109246611595154),\n",
       " (68, 0.30898165702819824),\n",
       " (237, 0.30855119228363037),\n",
       " (281, 0.30842432379722595),\n",
       " (160, 0.3071557283401489),\n",
       " (288, 0.3047647178173065),\n",
       " (298, 0.3010544776916504),\n",
       " (252, 0.2985289394855499),\n",
       " (183, 0.29780057072639465),\n",
       " (205, 0.2946704924106598),\n",
       " (217, 0.2945232391357422),\n",
       " (154, 0.2926265001296997),\n",
       " (24, 0.28819388151168823),\n",
       " (49, 0.28754478693008423),\n",
       " (31, 0.28391900658607483),\n",
       " (36, 0.28059107065200806),\n",
       " (28, 0.2798754572868347),\n",
       " (270, 0.2783772349357605),\n",
       " (80, 0.27655914425849915),\n",
       " (172, 0.27578380703926086),\n",
       " (100, 0.27573683857917786),\n",
       " (4, 0.2738242745399475),\n",
       " (56, 0.2731970548629761),\n",
       " (156, 0.27236589789390564),\n",
       " (12, 0.27070972323417664),\n",
       " (131, 0.270317018032074),\n",
       " (97, 0.26996105909347534),\n",
       " (95, 0.2698293924331665),\n",
       " (150, 0.2697692811489105),\n",
       " (285, 0.2689560353755951),\n",
       " (69, 0.26631152629852295),\n",
       " (210, 0.264539510011673),\n",
       " (162, 0.2609735131263733),\n",
       " (21, 0.2604942321777344),\n",
       " (25, 0.26033806800842285),\n",
       " (29, 0.26029255986213684),\n",
       " (248, 0.26027780771255493),\n",
       " (140, 0.2592634856700897),\n",
       " (94, 0.2587093710899353),\n",
       " (109, 0.25749778747558594),\n",
       " (114, 0.2530221939086914),\n",
       " (106, 0.2528407871723175),\n",
       " (57, 0.25239256024360657),\n",
       " (222, 0.2501153349876404),\n",
       " (108, 0.24644538760185242),\n",
       " (168, 0.24289795756340027),\n",
       " (251, 0.24152275919914246),\n",
       " (79, 0.2409459352493286),\n",
       " (103, 0.2408868372440338),\n",
       " (184, 0.24083715677261353),\n",
       " (173, 0.24006754159927368),\n",
       " (144, 0.2398778796195984),\n",
       " (148, 0.23695406317710876),\n",
       " (230, 0.23668572306632996),\n",
       " (33, 0.23668187856674194),\n",
       " (169, 0.235836923122406),\n",
       " (155, 0.23580947518348694),\n",
       " (51, 0.23571167886257172),\n",
       " (236, 0.23532119393348694),\n",
       " (3, 0.23197981715202332),\n",
       " (102, 0.23161421716213226),\n",
       " (54, 0.23027697205543518),\n",
       " (250, 0.22858721017837524),\n",
       " (117, 0.2282610535621643),\n",
       " (166, 0.22775214910507202),\n",
       " (201, 0.22769507765769958),\n",
       " (121, 0.22483181953430176),\n",
       " (120, 0.22053930163383484),\n",
       " (163, 0.21759387850761414),\n",
       " (89, 0.21535541117191315),\n",
       " (193, 0.21519190073013306),\n",
       " (234, 0.2149609923362732),\n",
       " (284, 0.21367664635181427),\n",
       " (176, 0.2121245265007019),\n",
       " (129, 0.2117890864610672),\n",
       " (133, 0.21015788614749908),\n",
       " (209, 0.2097744345664978),\n",
       " (273, 0.20897577702999115),\n",
       " (287, 0.2080238312482834),\n",
       " (10, 0.20788165926933289),\n",
       " (67, 0.20787757635116577),\n",
       " (276, 0.2075842171907425),\n",
       " (105, 0.20625755190849304),\n",
       " (256, 0.20598892867565155),\n",
       " (286, 0.20392771065235138),\n",
       " (137, 0.20353789627552032),\n",
       " (98, 0.2034863829612732),\n",
       " (279, 0.20284302532672882),\n",
       " (238, 0.20245003700256348),\n",
       " (295, 0.20244243741035461),\n",
       " (40, 0.20183269679546356),\n",
       " (239, 0.2016497403383255),\n",
       " (107, 0.19707703590393066),\n",
       " (41, 0.19501949846744537),\n",
       " (170, 0.1940968632698059),\n",
       " (202, 0.1931035816669464),\n",
       " (127, 0.19280022382736206),\n",
       " (124, 0.19166435301303864),\n",
       " (161, 0.19121848046779633),\n",
       " (22, 0.18946465849876404),\n",
       " (278, 0.18941962718963623),\n",
       " (211, 0.18933716416358948),\n",
       " (265, 0.18878823518753052),\n",
       " (2, 0.1884145438671112),\n",
       " (20, 0.18793851137161255),\n",
       " (116, 0.1877795159816742),\n",
       " (242, 0.18668749928474426),\n",
       " (8, 0.18655076622962952),\n",
       " (113, 0.185575470328331),\n",
       " (204, 0.18532542884349823),\n",
       " (262, 0.1841023713350296),\n",
       " (58, 0.18362754583358765),\n",
       " (101, 0.18042844533920288),\n",
       " (187, 0.17916256189346313),\n",
       " (65, 0.17641127109527588),\n",
       " (231, 0.1760547012090683),\n",
       " (292, 0.1693236529827118),\n",
       " (171, 0.16842728853225708),\n",
       " (78, 0.16838771104812622),\n",
       " (5, 0.16821476817131042),\n",
       " (188, 0.1671978384256363),\n",
       " (227, 0.16485878825187683),\n",
       " (91, 0.16290681064128876),\n",
       " (126, 0.16204170882701874),\n",
       " (99, 0.16187889873981476),\n",
       " (75, 0.1608186662197113),\n",
       " (63, 0.16043329238891602),\n",
       " (178, 0.15978671610355377),\n",
       " (30, 0.15777820348739624),\n",
       " (198, 0.15750998258590698),\n",
       " (125, 0.15588784217834473),\n",
       " (60, 0.1534406542778015),\n",
       " (44, 0.1508100926876068),\n",
       " (50, 0.1499391794204712),\n",
       " (240, 0.14985431730747223),\n",
       " (159, 0.1484750211238861),\n",
       " (296, 0.14752161502838135),\n",
       " (247, 0.14614896476268768),\n",
       " (138, 0.14491139352321625),\n",
       " (219, 0.14082154631614685),\n",
       " (290, 0.1407470852136612),\n",
       " (267, 0.13787831366062164),\n",
       " (62, 0.13781386613845825),\n",
       " (272, 0.13580310344696045),\n",
       " (291, 0.13544000685214996),\n",
       " (142, 0.13320133090019226),\n",
       " (244, 0.13232165575027466),\n",
       " (259, 0.13168436288833618),\n",
       " (235, 0.13159503042697906),\n",
       " (81, 0.13041552901268005),\n",
       " (226, 0.13040128350257874),\n",
       " (149, 0.13030830025672913),\n",
       " (179, 0.12643098831176758),\n",
       " (82, 0.12463110685348511),\n",
       " (197, 0.12436831742525101),\n",
       " (206, 0.1236027181148529),\n",
       " (34, 0.12304526567459106),\n",
       " (199, 0.1165996640920639),\n",
       " (9, 0.11554215848445892),\n",
       " (128, 0.11251918971538544),\n",
       " (135, 0.10844793170690536),\n",
       " (203, 0.10588343441486359),\n",
       " (192, 0.10392917692661285),\n",
       " (136, 0.10342779010534286),\n",
       " (88, 0.0986156016588211),\n",
       " (74, 0.09519408643245697),\n",
       " (147, 0.09199763834476471),\n",
       " (35, 0.09046716243028641),\n",
       " (14, 0.08845682442188263),\n",
       " (195, 0.08788849413394928),\n",
       " (122, 0.08760366588830948),\n",
       " (66, 0.08426101505756378),\n",
       " (85, 0.08096557855606079),\n",
       " (164, 0.07842975109815598),\n",
       " (84, 0.0762743353843689),\n",
       " (167, 0.07571779191493988),\n",
       " (48, 0.07068036496639252),\n",
       " (208, 0.06991304457187653),\n",
       " (277, 0.0665384978055954),\n",
       " (110, 0.06641547381877899),\n",
       " (1, 0.06634029746055603),\n",
       " (185, 0.06396400928497314),\n",
       " (0, 0.06103076785802841),\n",
       " (220, 0.0586368665099144),\n",
       " (145, 0.05329905450344086),\n",
       " (260, 0.05246863514184952),\n",
       " (255, 0.04905030503869057),\n",
       " (177, 0.04827098548412323),\n",
       " (153, 0.04681232199072838),\n",
       " (77, 0.04037198796868324),\n",
       " (141, 0.038136161863803864),\n",
       " (189, 0.03773662447929382),\n",
       " (257, 0.03726137429475784),\n",
       " (249, 0.03712351620197296),\n",
       " (93, 0.035911910235881805),\n",
       " (123, 0.0340319499373436),\n",
       " (11, 0.022776804864406586),\n",
       " (13, 0.021498538553714752),\n",
       " (151, 0.021242540329694748),\n",
       " (200, 0.02038884162902832),\n",
       " (86, 0.01816827803850174),\n",
       " (268, 0.01585674285888672),\n",
       " (143, 0.007257178425788879),\n",
       " (243, 0.00033158063888549805),\n",
       " (76, -0.013281263411045074),\n",
       " (216, -0.023258283734321594),\n",
       " (233, -0.03092869743704796),\n",
       " (87, -0.04720257222652435),\n",
       " (223, -0.054243303835392),\n",
       " (261, -0.07661572843790054)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (299): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (299, 0.9568108320236206): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "MEDIAN (102, 0.23161421716213226): «the secretary general of the law council michael lavarch says the government proposed new asio laws need guarantees to protect the rights of individuals the federal government wants to give officers the power to detain suspects for hours without legal representation asio already has the power to jail people for up to five years if they refuse to answer questions mr lavarch former labor attorney general says he is concerned asio could use the laws to detain people indefinitely the government yet to make its case it very draconian power and if it is required in order to protect public safety it absolutely essential that there be important safeguards he said»\n",
      "\n",
      "LEAST (261, -0.07661572843790054): «afghan opposition leaders meeting in germany have reached an agreement after seven days of talks on the structure of an interim post taliban government for afghanistan the agreement calls for the immediate assembly of temporary group of multi national peacekeepers in kabul and possibly other areas the four afghan factions have approved plan for member ruling council composed of chairman five deputy chairmen and other members the council would govern afghanistan for six months at which time traditional afghan assembly called loya jirga would be convened to decide on more permanent structure the agreement calls for elections within two years»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (30): «police are combing through videotapes trying to spot the gunman dressed in black who shot year old man to death at downtown massage parlour the victim was hit in the stomach and upper body and died about hours later in hospital the woman was not hurt police urged business owners to turn over any security camera videotapes they might have that recorded people on the street at the time several such videos are now being reviewed»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (219, 0.6975003480911255): «several people believed to be as many as have been shot at northern indiana factory in the united states police said the person who did the shooting was still inside the building preliminary reports suggested disgruntled employee might be behind the mass shooting at nu wood decorative millwork factory at the industrial park in goshen which occurred around pm local time am aedt we re hearing as many as have been shot but we can confirm that said goshen police dispatcher we haven been able to get inside she said the person who fired the shots at the factory near goshen was still inside the facility the city is about kilometres east of chicago»\n",
      "\n",
      "MEDIAN (166, 0.3854634165763855): «the federal government says asio and the australian federal police have interviewed the family of an australian man who has been fighting with the taliban in afghanistan the year old man was arrested by the northern alliance at the weekend the federal attorney general daryl williams says he cannot confirm media reports the man has family in adelaide but he says he has had more extensive training than american john walker lindh who was arrested on december for fighting with the taliban he is understood to have travelled to europe in mid to join the kosovo liberation army he then travelled to pakistan november where he undertook some training he entered afghanistan as we understand it in and he has actually undertaken extensive training with osama bin laden al qaeda network mr williams said»\n",
      "\n",
      "LEAST (251, 0.05339786037802696): «interest rates and economic growth take centre stage for australian financial markets today rates cut is still expected despite what is thought to be respectable set of national accounts the australian economy has been held up as one of the few to be still ticking over well while so many others around the world are in recession or slowing sharply today national accounts for the september quarter will be the definitive measure sg australia chief economist glenn maguire says he expects quarterly figure of just under per cent if we do see economic growth up around per cent which is the market consensus that is actually relatively very good outcome he said that would translate to an annual growth rate of per cent mr maguire says domestic economic activity remains centred on the housing sector think the national accounts will reveal that the bulk of economic growth is being driven by the housing sector and those areas which are related to the housing sector such as retail trade and manufacturing but he says some areas of weakness are emerging company profits were quite soft also average earnings are likely to post softer footing over the quarter as well so looking forward softer incomes probably softer production as well suggest that the domestic economy will be slowing as we move into mr maguire said financial markets are also waiting on possible announcement from the reserve bank after its board meeting of yesterday there is high level of expectation that rates will be cut by per cent the australian trade commission says there are signs of recovery on global markets three months after the september terrorist attacks senior austrade staff from across the globe are in adelaide to discuss the impact of the attack on the us and major international markets austrade executive general manager roger bayliss says the vast majority of global equity markets have bounced back and growth is expected to return by the third quarter of next year mr bayliss says while there are serious challenges ahead australian firms should not retreat the most important point is to really study your markets get good advice make sure you re looking after your customers well and certainly not staying in your shell or in your cocoon and adopting very aggressive approach to overseas marketing mr bayliss said»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
